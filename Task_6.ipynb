{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "116ca0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e5053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = r'E:\\AIML Tasks\\Nike_Sales_Uncleaned.csv'\n",
    "OUTPUT_IMAGE_ELBOW = 'cluster_elbow_curve.png'\n",
    "OUTPUT_IMAGE_KMEANS = 'cluster_kmeans_pca.png'\n",
    "OUTPUT_IMAGE_HIERARCHICAL = 'cluster_hierarchical.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4d51728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads the raw Nike dataset and performs extensive cleaning:\n",
    "    1. Removes non-numeric characters from currency fields.\n",
    "    2. Converts dates.\n",
    "    3. Handles missing values.\n",
    "    \"\"\"\n",
    "    print(\"Loading and cleaning data...\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Standardizing column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # List of columns that are likely currency/numeric but might be dirty\n",
    "    currency_cols = ['revenue', 'profit', 'mrp']\n",
    "    \n",
    "    for col in currency_cols:\n",
    "        if col in df.columns:\n",
    "            # Remove '$', ',', and whitespace, then convert to float\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].replace(r'[$,\\s]', '', regex=True)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # 'units_sold' usually has commas\n",
    "    if 'units_sold' in df.columns:\n",
    "        if df['units_sold'].dtype == 'object':\n",
    "            df['units_sold'] = df['units_sold'].replace(r'[,]', '', regex=True)\n",
    "        df['units_sold'] = pd.to_numeric(df['units_sold'], errors='coerce')\n",
    "\n",
    "    # Drop rows with nulls in critical columns\n",
    "    clean_df = df.dropna(subset=['revenue', 'profit', 'units_sold'])\n",
    "    \n",
    "    print(f\"Data cleaned. Rows remaining: {len(clean_df)}\")\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfc8bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df):\n",
    "    \"\"\"\n",
    "    Selects numerical features for clustering and scales them.\n",
    "    \"\"\"\n",
    "    # UPDATED: Selecting key metrics for segmentation using CORRECT names\n",
    "    features = ['revenue', 'profit', 'units_sold']\n",
    "    X = df[features]\n",
    "    \n",
    "    # Standardization is crucial for K-Means\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "601ebcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_k(X_scaled):\n",
    "    \"\"\"\n",
    "    Uses the Elbow Method and Silhouette Score to find optimal K.\n",
    "    \"\"\"\n",
    "    print(\"Determining optimal cluster count (K)...\")\n",
    "    inertia = []\n",
    "    silhouette_scores = []\n",
    "    k_range = range(2, 11)\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_scaled)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "        \n",
    "    # Plotting Elbow Curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(k_range, inertia, marker='o', linestyle='--')\n",
    "    plt.title('Elbow Method for Optimal K')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(OUTPUT_IMAGE_ELBOW)\n",
    "    plt.close()\n",
    "    \n",
    "    # Automatically select K with highest silhouette score\n",
    "    best_k = k_range[np.argmax(silhouette_scores)]\n",
    "    print(f\"Optimal K based on Silhouette Score: {best_k}\")\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "796e0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(X_scaled, k):\n",
    "    \"\"\"\n",
    "    Trains K-Means model and visualizes results using PCA (2D projection).\n",
    "    \"\"\"\n",
    "    print(f\"Training K-Means with K={k}...\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Use PCA to reduce dimensions to 2 for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='viridis', s=100)\n",
    "    plt.title(f'K-Means Clustering (PCA Projection, K={k})')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(title='Cluster')\n",
    "    plt.savefig(OUTPUT_IMAGE_KMEANS)\n",
    "    plt.close()\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1becb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hierarchical(X_scaled, k):\n",
    "    \"\"\"\n",
    "    Trains Agglomerative (Hierarchical) Clustering.\n",
    "    \"\"\"\n",
    "    print(\"Training Hierarchical Clustering...\")\n",
    "    hc = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "    clusters = hc.fit_predict(X_scaled)\n",
    "    \n",
    "    # Visualization (using same PCA for consistency)\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='magma', s=100)\n",
    "    plt.title(f'Hierarchical Clustering (PCA Projection, K={k})')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.savefig(OUTPUT_IMAGE_HIERARCHICAL)\n",
    "    plt.close()\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9aaf192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cleaning data...\n",
      "Data cleaned. Rows remaining: 1265\n",
      "Determining optimal cluster count (K)...\n",
      "Optimal K based on Silhouette Score: 6\n",
      "Training K-Means with K=6...\n",
      "Training Hierarchical Clustering...\n",
      "Analysis complete. Clustered data saved to Nike_Sales_Clustered.csv\n",
      "\n",
      "--- Cluster Profiling (Mean Values) ---\n",
      "                     revenue       profit  units_sold\n",
      "kmeans_cluster                                       \n",
      "0                 -40.787953  2642.567148    0.003356\n",
      "1                  66.236986    36.144681    2.960993\n",
      "2                 -35.448478   162.983913   -0.046584\n",
      "3               21549.624545  1498.572727    3.363636\n",
      "4                  37.300234  2649.511371    2.973244\n",
      "5                8375.019623  1402.122453    2.415094\n"
     ]
    }
   ],
   "source": [
    "# --- Execution Flow ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Data\n",
    "    df = load_and_clean_data(DATA_PATH)\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    X_scaled, feature_names = preprocess_features(df)\n",
    "    \n",
    "    # 3. Find K\n",
    "    optimal_k = determine_optimal_k(X_scaled)\n",
    "    \n",
    "    # 4. K-Means Clustering\n",
    "    df['kmeans_cluster'] = run_kmeans(X_scaled, optimal_k)\n",
    "    \n",
    "    # 5. Hierarchical Clustering\n",
    "    df['hierarchical_cluster'] = run_hierarchical(X_scaled, optimal_k)\n",
    "    \n",
    "    # 6. Save Results\n",
    "    output_csv = 'Nike_Sales_Clustered.csv'\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Analysis complete. Clustered data saved to {output_csv}\")\n",
    "    \n",
    "    # 7. Simple Analysis of Clusters\n",
    "    # UPDATED: Using correct column names for analysis\n",
    "    print(\"\\n--- Cluster Profiling (Mean Values) ---\")\n",
    "    print(df.groupby('kmeans_cluster')[['revenue', 'profit', 'units_sold']].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
